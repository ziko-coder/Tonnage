{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5afd6013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import MissingIndicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a5381bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_name = '../data/train_set.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd30dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66aad1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'DTronc', 'LTronc', 'DChar', 'LChar', 'DChar1', 'LChar1',\n",
       "       'DChar2', 'LChar2', 'DChar3', 'LChar3', 'DChar4', 'LChar4', 'PFr1',\n",
       "       'PFr2', 'PFr3', 'PFr4', 'PFr6', 'DChar5', 'LChar5', 'PFr5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d26ad23",
   "metadata": {},
   "source": [
    "# Target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be9b1196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get rid of typos and unwanted strings\n",
    "def convert_to_nan(x):\n",
    "    try:\n",
    "        return pd.to_numeric(x)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d45c348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "def process_column(df, column_name, strategy):\n",
    "    # Convert column values to NaN\n",
    "    df[column_name] = df[column_name].apply(convert_to_nan)\n",
    "    \n",
    "    # Impute missing values using SimpleImputer\n",
    "    df[column_name] = imputer.fit_transform(df[column_name].values.reshape(-1, 1))\n",
    "    \n",
    "    # Scale the resulting column using MinMaxScaler  \n",
    "    df[column_name] = scaler.fit_transform(df[column_name].values.reshape(-1, 1))\n",
    "    \n",
    "    # Pickle the variables\n",
    "    with open('scaler.pkl', 'wb') as file:\n",
    "        pickle.dump(scaler, file)\n",
    "    with open('imputer.pkl', 'wb') as file:\n",
    "        pickle.dump(imputer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaeb0235",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['PFr1', 'PFr2','PFr3', 'PFr4', 'PFr5', 'PFr6']\n",
    "\n",
    "for i in cols:\n",
    "    process_column(df, i, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b027b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sum'] = df[['PFr1', 'PFr2', 'PFr3', 'PFr4', 'PFr5', 'PFr6']].sum(axis=1)\n",
    "df['Sum'] = scaler.fit_transform(df['Sum'].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e06490",
   "metadata": {},
   "source": [
    "# Input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54a45bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_with_zero(df, column_name):\n",
    "    df.loc[:, column_name].fillna(0, inplace=True)\n",
    "\n",
    "def convert_column_to_float32(df, column_name):\n",
    "    df[column_name] = df[column_name].replace([np.inf, -np.inf], np.nan)\n",
    "    df[column_name].fillna(0, inplace=True)\n",
    "    df[column_name] = df[column_name].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1114e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['DTronc', 'LTronc', 'DChar', 'LChar', 'DChar1', 'LChar1', 'DChar2', 'LChar2', 'DChar3', 'LChar3', 'DChar4', 'LChar4']\n",
    "\n",
    "for col in cols:\n",
    "    df[col] = df[col].apply(convert_to_nan)\n",
    "    \n",
    "\n",
    "for c in cols:\n",
    "    convert_column_to_float32(df, c)\n",
    "    \n",
    "for c in cols:\n",
    "    df[c] = scaler.fit_transform(df[c].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4176c017",
   "metadata": {},
   "source": [
    "# Creating multiple sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4dfb29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['DTronc', 'LTronc', 'DChar', 'LChar', 'DChar1', 'LChar1', 'Sum']]\n",
    "\n",
    "df2 = df[['DTronc', 'LTronc', 'DChar', 'LChar', 'DChar1', 'LChar1', 'DChar2', 'LChar2', 'Sum']]\n",
    "\n",
    "df3 = df[['DTronc', 'LTronc', 'DChar', 'LChar', 'DChar1', 'LChar1', 'DChar2',\n",
    "       'LChar2', 'DChar3', 'LChar3', 'Sum']]\n",
    "\n",
    "df4 = df[['DTronc', 'LTronc', 'DChar', 'LChar', 'DChar1', 'LChar1', 'DChar2',\n",
    "       'LChar2', 'DChar4', 'LChar4', 'Sum']]\n",
    "\n",
    "df5 = df[['DTronc', 'LTronc', 'DChar', 'LChar', 'DChar1', 'LChar1', 'DChar2',\n",
    "       'LChar2', 'DChar5', 'LChar5', 'Sum']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bfc9cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sheets_names = ['../data/precoce_1_Char_mean.csv',\n",
    "                   '../data/precoce_2_Char_mean.csv',\n",
    "                   '../data/precoce_3_Char_mean.csv',\n",
    "                   '../data/precoce_4_Char_mean.csv',\n",
    "                    '../data/precoce_5_Char_mean.csv'\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5c6b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(new_sheets_names[0])\n",
    "df2.to_csv(new_sheets_names[1])\n",
    "df3.to_csv(new_sheets_names[2])\n",
    "df4.to_csv(new_sheets_names[3])\n",
    "df5.to_csv(new_sheets_names[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
